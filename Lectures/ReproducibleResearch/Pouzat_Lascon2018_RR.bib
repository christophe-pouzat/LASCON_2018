% This file was created with JabRef 2.6.
% Encoding: UTF8

@BOOK{Adler:2009,
  title = {R IN A NUTSHELL},
  publisher = {0'REILLY},
  year = {2009},
  author = {Joseph Adler},
  owner = {xtof},
  timestamp = {2011.05.02}
}

@ELECTRONIC{ALPSP-STM-data-accessibility,
  author = {ALPSP-STM},
  month = {jun},
  year = {2006},
  title = {ALPSP-STM Statement on Data and Databases},
  language = {English},
  organization = {Association of Learned and Professional Society Publishers - International
	Association of Scientific, Technical \& Medical Publishers},
  url = {www.alpsp.org/ForceDownload.asp?id=129},
  file = {ALPSP-STM-data-accessibility.pdf:Reproducible_Research/ALPSP-STM-data-accessibility.pdf:PDF},
  owner = {xtof},
  timestamp = {2011.01.27}
}

@TECHREPORT{AndersonDewald_1994,
  author = {Richard G. Anderson and William G. Dewald},
  title = {Replication and Scientific Standards in Economics a Decade Later:
	The Impact of the JMCB Project},
  institution = {Federal Reserve Bank of St. Louis},
  year = {1994},
  type = {Working Paper},
  number = {1994-007C},
  note = {Available at: \url{http://research.stlouisfed.org/wp/more/1994-007/}},
  abstract = {Scientific inquiry embodies skepticism. Researchers are trained to
	scrutinize every result, doubting not only the truth but also the
	tests of every hypothesis. Research papers in professional journals
	typically present only summaries of results, however, providing neither
	the programs nor data that a reader requires fully understanding
	-- and questioning -- the authors' tests. The Journal of Money, Credit,
	and Banking project a decade ago was the first attempt by the editor
	of a major journal to furnish readers with the data and programs
	used by the journal's authors. The project revealed the futility
	of proposing that readers obtain data and programs directly from
	authors, since data often were lost during the long interval between
	completion of the research and appearance of the published article.
	The project also established that professional journals were a low
	cost mechanism for collecting data from authors and distributing
	it to readers. A decade later, although the JMCB no longer requests
	data from authors, 2 journals have recently begun collecting such
	data and distributing it via the Internet.},
  file = {AndersonDewald_1994.pdf:Reproducible_Research/AndersonDewald_1994.pdf:PDF},
  owner = {xtof},
  timestamp = {2011.01.24},
  url = {http://research.stlouisfed.org/wp/more/1994-007/}
}

@ARTICLE{Baggerly_2010,
  author = {Baggerly, Keith},
  title = {Disclose all data in publications},
  journal = {Nature},
  year = {2010},
  volume = {467},
  pages = {401--401},
  number = {7314},
  month = sep,
  comment = {10.1038/467401b},
  file = {Baggerly_2010.pdf:Reproducible_Research/Baggerly_2010.pdf:PDF},
  issn = {0028-0836},
  owner = {xtof},
  publisher = {Nature Publishing Group, a division of Macmillan Publishers Limited.
	All Rights Reserved.},
  timestamp = {2011.02.01},
  url = {http://dx.doi.org/10.1038/467401b}
}

@ARTICLE{BaggerlyCoombes_2009,
  author = {Keith A. Baggerly and Kevin R. Coombes},
  title = {Deriving chemosensitivity from cell lines: Forensic bioinformatics
	and reproducible research in high-throughput biology},
  journal = {Annals of Applied Statistics},
  year = {2009},
  volume = {3},
  pages = {1309-1334},
  number = {4},
  note = {Preprint available at: \url{http://arxiv.org/abs/1010.1092}},
  abstract = {High-throughput biological assays such as microarrays let us ask very
	detailed questions about how diseases operate, and promise to let
	us personalize therapy. Data processing, however, is often not described
	well enough to allow for exact reproduction of the results, leading
	to exercises in “forensic bioinformatics” where aspects of raw data
	and reported results are used to infer what methods must have been
	employed. Unfortunately, poor documentation can shift from an inconvenience
	to an active danger when it obscures not just methods but errors.
	In this report we examine several related papers purporting to use
	microarray-based signatures of drug sensitivity derived from cell
	lines to predict patient response. Patients in clinical trials are
	currently being allocated to treatment arms on the basis of these
	results. However, we show in five case studies that the results incorporate
	several simple errors that may be putting patients at risk. One theme
	that emerges is that the most common errors are simple (e.g., row
	or column offsets); conversely, it is our experience that the most
	simple errors are common. We then discuss steps we are taking to
	avoid such errors in our own investigations.},
  doi = {10.1214/09-AOAS291},
  file = {BaggerlyCoombes_2009.pdf:Reproducible_Research/BaggerlyCoombes_2009.pdf:PDF},
  owner = {xtof},
  timestamp = {2011.02.01},
  url = {http://projecteuclid.org/euclid.aoas/1267453942}
}

@BOOK{deBoor_2001,
  title = {A Practical Guide to Splines, Revised Edition},
  publisher = {Springer},
  year = {2001},
  author = {Carl de Boor},
  pages = {xviii + 346p},
  address = {New York},
  owner = {xtof},
  timestamp = {2011.02.16}
}

@INBOOK{BuckheitDonoho_1995,
  chapter = {Wavelab and Reproducible Research},
  title = {{W}avelets and {S}tatistics},
  publisher = {Springer},
  year = {1995},
  editor = {Antoniadis, A.},
  author = {Buckheit, Jonathan B. and Donoho, David L.},
  note = {Preprint available at: \url{http://www-stat.stanford.edu/~wavelab/Wavelab_850/wavelab.pdf}},
  file = {BuckheitDonoho_1995.pdf:Reproducible_Research/BuckheitDonoho_1995.pdf:PDF},
  owner = {xtof},
  timestamp = {2008.03.14}
}

@ARTICLE{Buzsaki_2004,
  author = {Gy\"orgy Buzs\'aki},
  title = {{L}arge-scale recording of neuronal ensembles.},
  journal = {Nat Neurosci},
  year = {2004},
  volume = {7},
  pages = {446--451},
  number = {5},
  month = {May},
  abstract = {How does the brain orchestrate perceptions, thoughts and actions from
	the spiking activity of its neurons? Early single-neuron recording
	research treated spike pattern variability as noise that needed to
	be averaged out to reveal the brain's representation of invariant
	input. Another view is that variability of spikes is centrally coordinated
	and that this brain-generated ensemble pattern in cortical structures
	is itself a potential source of cognition. Large-scale recordings
	from neuronal ensembles now offer the opportunity to test these competing
	theoretical frameworks. Currently, wire and micro-machined silicon
	electrode arrays can record from large numbers of neurons and monitor
	local neural circuits at work. Achieving the full potential of massively
	parallel neuronal recordings, however, will require further development
	of the neuron-electrode interface, automated and efficient spike-sorting
	algorithms for effective isolation and identification of single neurons,
	and new mathematical insights for the analysis of network properties.},
  doi = {10.1038/nn1233},
  keywords = {Action Potentials; Animals; Brain; Electrophysiology; Humans; Microelectrodes;
	Nerve Net; Neurons; Neurophysiology},
  owner = {xtof},
  pii = {nn1233},
  pmid = {15114356},
  timestamp = {2008.03.14},
  url = {http://dx.doi.org/10.1038/nn1233}
}

@ARTICLE{ChandraOptican_1997,
  author = {R. Chandra and L. M. Optican},
  title = {{D}etection, classification, and superposition resolution of action
	potentials in multiunit single-channel recordings by an on-line real-time
	neural network.},
  journal = {IEEE Trans Biomed Eng},
  year = {1997},
  volume = {44},
  pages = {403--412},
  number = {5},
  month = {May},
  note = {Available at: \url{http://lsr-web.net/Assets/NEIPages/LanceOptican/pdf/chandra_optican_1997.pdf}},
  abstract = {Determination of single-unit spike trains from multiunit recordings
	obtained during extracellular recording has been the focus of many
	studies over the last two decades. In multiunit recordings, superpositions
	can occur with high frequency if the firing rates of the neurons
	are high or correlated, making superposition resolution imperative
	for accurate spike train determination. In this work, a connectionist
	neural network (NN) was applied to the spike sorting challenge. A
	novel training scheme was developed which enabled the NN to resolve
	some superpositions using single-channel recordings. Simulated multiunit
	spike trains were constructed from templates and noise segments that
	were extracted from real extracellular recordings. The simulations
	were used to determine the performances of the NN and a simple matched
	template filter (MTF), which was used as a basis for comparison.
	The network performed as well as the MTF in identifying nonoverlapping
	spikes, and was significantly better in resolving superpositions
	and rejecting noise. An on-line, real-time implementation of the
	NN discriminator, using a high-speed digital signal processor mounted
	inside an IBM-PC, is now in use in six laboratories.},
  file = {ChandraOptican_1997.pdf:Spike_Sorting/ChandraOptican_1997.pdf:PDF},
  keywords = {Action Potentials; Algorithms; Analog-Digital Con; Animals; False
	Positive Reactions; Haplorhini; Humans; Infant, Newborn; Models,
	Neurological; Neural Networks (Computer); Online Systems; Sensitivity
	and Specificity; Signal Processing, Computer-Assisted; Temporal Lobe;
	version},
  owner = {xtof},
  pmid = {9125825},
  timestamp = {2008.03.14}
}

@INPROCEEDINGS{ClaerboutKarrenbach_1992,
  author = {Jon Claerbout and Martin Karrenbach},
  title = {Electronic Documents Give Reproducible Research a New Meaning},
  booktitle = {Proceedings of the 62nd Annual Meeting of the Society of Exploration
	Geophysics},
  year = {1992},
  pages = {601-604},
  note = {Available at: \url{http://sepwww.stanford.edu/doku.php?id=sep:research:reproducible:seg92}},
  owner = {xtof},
  timestamp = {2011.01.20},
  url = {http://sepwww.stanford.edu/doku.php?id=sep:research:reproducible:seg92}
}

@BOOK{CookSwayne_2007,
  title = {{Interactive and Dynamic Graphics for Data Analysis. With R and GGobi}},
  publisher = {Springer},
  year = {2007},
  editor = {Robert Gentleman and Kurt Hornik and Giovanni Parmigiani},
  author = {Dianne Cook and Deborah F. Swayne},
  file = {CookSwayne_2007.pdf:Books/CookSwayne_2007.pdf:PDF},
  owner = {xtof},
  timestamp = {2011.02.08}
}

@PHDTHESIS{Delescluse:2005,
  author = {Matthieu Delescluse},
  title = {Une approche Monte Carlo par Chaînes de Markov pour la classification
	des potentiels d'action.
	
	Application à l'étude des corrélations d'activité des cellules de
	Purkinje.},
  school = {Université Pierre et Marie Curie},
  year = {2005},
  note = {Available at: \url{http://tel.archives-ouvertes.fr/tel-00011123/fr/}},
  abstract = {Pour être réellement exploitables, les données d'enregistrements extracellulaires
	multiunitaires doivent faire l'objet d'un traitement préalable visant
	à isoler les activités neuronales individuelles qui les constituent:
	le spike-sorting. Ce travail de thèse est une contribution au développement
	et à la réalisation d'une méthode automatique de spike-sorting implémentant
	un algorithme de Monte Carlo par Chaînes de Markov (MCMC). La méthode
	proposée permet de tenir compte, en plus de la forme des potentiels
	d'action (PAs), de l'information fournie par leurs temps d'émission
	pour réaliser la classification. Cette utilisation de l'information
	temporelle rend possible l'identification automatique de neurones
	émettant des PAs de formes non stationnaires. Elle améliore aussi
	grandement la séparation de neurones aux PAs de formes similaires.
	Ce travail méthodologique à débouché sur la création d'un logiciel
	libre accompagné de son manuel d'utilisateur.
	
	Cette méthode de spike-sorting a fait l'objet d'une validation expérimentale
	sur des populations de cellules de Purkinje (PCs), dans les tranches
	de cervelet de rat. Par ailleurs, l'étude des trains de PAs de ces
	cellules fournis par le spike-sorting, n'a pas révélé de corrélations
	temporelles significatives en régime spontané, en dépit de l'existence
	d'une inhibition commune par les interneurones de la couche moléculaire
	et d'une inhibition directe de PC à PC. Des simulations ont montré
	que l'influence de ces inhibitions sur les relations temporelles
	entre les trains de PCs était trop faible pour pouvoir être détectée
	par nos méthodes d'analyse de corrélations. Les codes élaborés pour
	l'analyse des trains de PAs sont également disponibles sous la forme
	d'un second logiciel libre.},
  owner = {xtof},
  timestamp = {2011.05.05},
  url = {http://tel.archives-ouvertes.fr/tel-00011123/fr/}
}

@ARTICLE{DelesclusePouzat_2005,
  author = {Delescluse, Matthieu and Pouzat, Christophe},
  title = {{E}fficient spike-sorting of multi-state neurons using inter-spike
	intervals information},
  journal = {J Neurosci Methods},
  year = {2006},
  volume = {150},
  pages = {16--29},
  number = {1},
  month = {15 } # jan,
  note = {Also available on the arXiv pre-print server: q-bio/0505053; \url{http://arxiv.org/abs/q-bio/0505053}},
  abstract = {We demonstrate the efficacy of a new spike-sorting method based on
	a Markov Chain Monte Carlo (MCMC) algorithm by applying it to real
	data recorded from Purkinje cells (PCs) in young rat cerebellar slices.
	This algorithm is unique in its capability to estimate and make use
	of the firing statistics as well as the spike amplitude dynamics
	of the recorded neurons. PCs exhibit multiple discharge states, giving
	rise to multimodal interspike interval (ISI) histograms and to correlations
	between successive ISIs. The amplitude of the spikes generated by
	a PC in an "active" state decreases, a feature typical of many neurons
	from both vertebrates and invertebrates. These two features constitute
	a major and recurrent problem for all the presently available spike-sorting
	methods. We first show that a Hidden Markov Model with 3 log-Normal
	states provides a flexible and satisfying description of the complex
	firing of single PCs. We then incorporate this model into our previous
	MCMC based spike-sorting algorithm (Pouzat et al, 2004, J. Neurophys.
	91, 2910-2928) and test this new algorithm on multi-unit recordings
	of bursting PCs. We show that our method successfully classifies
	the bursty spike trains fired by PCs by using an independent single
	unit recording from a patch-clamp pipette.},
  authors = {Delescluse, Matthieu and Pouzat, Christophe},
  discloc = {file:///home/xtof/PaperPDF/Spike_Sorting/DelesclusePouzat_2006.pdf},
  doi = {10.1016/j.jneumeth.2005.05.023},
  eprint = {http://arxiv.org/abs/q-bio/0505053},
  file = {DelesclusePouzat_2006.pdf:Spike_Sorting/DelesclusePouzat_2006.pdf:PDF},
  keywords = {Markov chain Monte Carlo; Multi-electrode; Hidden Markov model; Purkinje
	cell},
  owner = {xtof},
  timestamp = {2008.03.14},
  url = { http://arxiv.org/abs/q-bio/0505053 }
}

@ARTICLE{DewaldEtAl_1986,
  author = {Dewald, William G. and Thursby, Jerry G. and Anderson, Richard G.},
  title = {Replication in Empirical Economics: The Journal of Money, Credit,
	and Banking Project.},
  journal = {American Economic Review},
  year = {1986},
  volume = {76},
  pages = {587-603},
  number = {4},
  abstract = {This paper examines the role of replication in empirical economic
	research. It presents the findings of a two-year study that collected
	programs and data from authors and attempted to replicate their published
	results. Our research provides new and important information about
	the extent and causes of failures to replicate published results
	in economics. Our findings suggest that inadvertent errors in published
	empirical articles are a commonplace rather than a rare occurrence.
	[ABSTRACT FROM AUTHOR]},
  file = {DewaldEtAl_1986.pdf:Reproducible_Research/DewaldEtAl_1986.pdf:PDF},
  issn = {00028282},
  keywords = {ECONOMICS -- Research, ECONOMICS, MONEY, CREDIT, RESEARCH, BANKS &
	banking, PROJECT finance, FINANCE, REPLICATION (Experimental design)},
  owner = {xtof},
  timestamp = {2011.01.24},
  url = {http://search.ebscohost.com/login.aspx?direct=true&db=buh&AN=4497372&site=ehost-live}
}

@ARTICLE{DiggleZeger_2010,
  author = {Diggle, Peter J. and Zeger, Scott L.},
  title = {Editorial},
  journal = {Biostatistics},
  year = {2010},
  volume = {11},
  pages = {375--375},
  number = {3},
  month = jul,
  comment = {10.1093/biostatistics/kxq029},
  file = {DiggleZeger_2010.pdf:Reproducible_Research/DiggleZeger_2010.pdf:PDF},
  owner = {xtof},
  timestamp = {2011.01.19},
  url = {http://biostatistics.oxfordjournals.org/content/11/3/375.short}
}

@TECHREPORT{DonohoEtAl_2008,
  author = {David Donoho and Arian Maleki and Morteza Shahram and Victoria Stodden
	and Inam Ur-Rahman},
  title = {{F}ifteen {Y}ears of {R}eproducible {R}esearch in {C}omputational
	{H}armonic {A}nalysis},
  institution = {Stanford University},
  year = {2008},
  month = {apr},
  note = {Available at: \url{http://www-stat.stanford.edu/~donoho/Reports/2008/15YrsReproResch-20080426.pdf}.},
  file = {DonohoEtAl_2008.pdf:Reproducible_Research/DonohoEtAl_2008.pdf:PDF},
  owner = {xtof},
  timestamp = {2010.05.15}
}

@ARTICLE{DonohoEtAl_2009,
  author = {David L. Donoho and Arian Maleki and Inam Ur Rahman and Morteza Shahram
	and Victoria Stodden},
  title = {Reproducible Research in Computational Harmonic Analysis},
  journal = {Computing in Science and Engineering},
  year = {2009},
  volume = {11},
  pages = {8-18},
  note = {Preprint available at: \url{http://www-stat.stanford.edu/~donoho/Reports/2008/15YrsReproResch-20080426.pdf}},
  address = {Los Alamitos, CA, USA},
  doi = {http://doi.ieeecomputersociety.org/10.1109/MCSE.2009.15},
  issn = {1521-9615},
  owner = {xtof},
  publisher = {IEEE Computer Society},
  timestamp = {2011.01.19}
}

@ELECTRONIC{ElsevierGuidelines,
  author = {Elsevier},
  year = {2011},
  title = {Ethical Guidelines for Journal Publication},
  language = {English},
  howpublished = {web},
  url = {http://www.elsevier.com/wps/find/intro.cws_home/ethical_guidelines#Duties%20of%20Authors},
  owner = {xtof},
  timestamp = {2011.01.27}
}

@BOOKLET{ESF-DFG_2007,
  title = {Shared Responsibilities in Sharing Research Data: Policies and Partnerships.
	Reports of an ESF-DFG workshop, 21 September 2007},
  author = {{ESF}},
  howpublished = {Web},
  lastchecked = {2011-01-27},
  year = {2007},
  note = {Available at: \url{www.dfg.de/download/pdf/.../sharing_research_data_esf_dfg_0709.pdf}},
  file = {sharing_research_data_esf_dfg_0709.pdf:Reproducible_Research/sharing_research_data_esf_dfg_0709.pdf:PDF},
  owner = {xtof},
  timestamp = {2011.01.27},
  url = {www.dfg.de/download/pdf/.../sharing_research_data_esf_dfg_0709.pdf}
}

@ARTICLE{FomelClaerbout_2009,
  author = {Sergey Fomel and Jon F. Claerbout},
  title = {Guest Editors' Introduction: Reproducible Research},
  journal = {Computing in Science and Engineering},
  year = {2009},
  volume = {11},
  pages = {5-7},
  address = {Los Alamitos, CA, USA},
  doi = {http://doi.ieeecomputersociety.org/10.1109/MCSE.2009.14},
  file = {FomelClaerbout_2009.pdf:Reproducible_Research/FomelClaerbout_2009.pdf:PDF},
  issn = {1521-9615},
  owner = {xtof},
  publisher = {IEEE Computer Society},
  timestamp = {2011.01.21}
}

@INPROCEEDINGS{FomelHennenfent_2007,
  author = {S. Fomel and G. Hennenfent},
  title = {Reproducible Computational Experiments Using Scons},
  booktitle = {Proc. IEEE Int'l Conf. Acoustics, Speech and Signal Processing},
  year = {2007},
  number = {4},
  pages = {IV1257–IV1260},
  file = {FomelHennenfent_2007.pdf:Reproducible_Research/FomelHennenfent_2007.pdf:PDF},
  owner = {xtof},
  timestamp = {2011.01.21},
  url = {http://www.reproducibility.org/RSF/book/rsf/scons/paper_html/}
}

@ARTICLE{FrankeEtAl_2010,
  author = {Franke, Felix and Natora, Michal and Boucsein, Clemens and Munk,
	Matthias and Obermayer, Klaus},
  title = {An online spike detection and spike classification algorithm capable
	of instantaneous resolution of overlapping spikes},
  journal = {Journal of Computational Neuroscience},
  year = {2010},
  volume = {29},
  pages = {127-148},
  note = {10.1007/s10827-009-0163-5},
  abstract = {For the analysis of neuronal cooperativity, simultaneously recorded
	extracellular signals from neighboring neurons need to be sorted
	reliably by a spike sorting method. Many algorithms have been developed
	to this end, however, to date, none of them manages to fulfill a
	set of demanding requirements. In particular, it is desirable to
	have an algorithm that operates online, detects and classifies overlapping
	spikes in real time, and that adapts to non-stationary data. Here,
	we present a combined spike detection and classification algorithm,
	which explicitly addresses these issues. Our approach makes use of
	linear filters to find a new representation of the data and to optimally
	enhance the signal-to-noise ratio. We introduce a method called Deconfusion
	which de-correlates the filter outputs and provides source separation.
	Finally, a set of well-defined thresholds is applied and leads to
	simultaneous spike detection and spike classification. By incorporating
	a direct feedback, the algorithm adapts to non-stationary data and
	is, therefore, well suited for acute recordings. We evaluate our
	method on simulated and experimental data, including simultaneous
	intra/extra-cellular recordings made in slices of a rat cortex and
	recordings from the prefrontal cortex of awake behaving macaques.
	We compare the results to existing spike detection as well as spike
	sorting methods. We conclude that our algorithm meets all of the
	mentioned requirements and outperforms other methods under realistic
	signal-to-noise ratios and in the presence of overlapping spikes.},
  affiliation = {Bernstein Center for Computational Neuroscience, Berlin, 10099 Germany},
  file = {FrankeEtAl_2010.pdf:Spike_Sorting/FrankeEtAl_2010.pdf:PDF},
  issn = {0929-5313},
  issue = {1},
  keyword = {Computer Science},
  owner = {xtof},
  publisher = {Springer Netherlands},
  timestamp = {2011.02.08},
  url = {http://dx.doi.org/10.1007/s10827-009-0163-5}
}

@ARTICLE{GentlemanTempleLang_2007,
  author = {Gentleman, Robert and Temple Lang, Duncan},
  title = {{S}tatistical {A}nalyses and {R}eproducible {R}esearch},
  journal = {Journal of Computational and Graphical Statistics},
  year = {2007},
  volume = {16},
  pages = {1-23},
  number = {1},
  abstract = {It is important, if not essential, to integrate the computations and
	code used in data analyses, methodological descriptions, simulations,
	and so on with the documents that describe and rely on them. This
	integration allows readers to both verify and adapt the claims in
	the documents. Authors can easily reproduce the results in the future,
	and they can present the document's contents in a different medium,
	for example, with interactive controls. This article describes a
	software framework for both authoring and distributing these integrated,
	dynamic documents that contain text, code, data, and any auxiliary
	content needed to recreate the computations. The documents are dynamic
	in that the contents—including figures, tables, and so on—can be
	recalculated each time a view of the document is generated. Our model
	treats a dynamic document as a master or “source” document from which
	one can generate different views in the form of traditional, derived
	documents for different audiences.
	
	We introduce the concept of a compendium as a container for one or
	more dynamic documents and the different elements needed when processing
	them, such as code and data. The compendium serves as a means for
	distributing, managing, and updating the collection.},
  doi = {10.1198/106186007X178663},
  eprint = {http://pubs.amstat.org/doi/pdf/10.1198/106186007X178663},
  owner = {xtof},
  timestamp = {2010.04.03},
  url = {http://pubs.amstat.org/doi/abs/10.1198/106186007X178663}
}

@TECHREPORT{GentlemanTempleLang_2004,
  author = {Gentleman, Robert and Temple Lang, Duncan},
  title = {{S}tatistical {A}nalyses and {R}eproducible {R}esearch},
  institution = {Bioconductor Project Working Papers},
  year = {2004},
  type = {Working Paper},
  number = {2},
  month = {29 } # may,
  note = {Available at: \url{http://www.bepress.com/bioconductor/paper2/}},
  abstract = {For various reasons, it is important, if not essential, to integrate
	the computations and code used in data analyses, methodological descriptions,
	simulations, etc. with the documents that describe and rely on them.
	This integration allows readers to both verify and adapt the statements
	in the documents. Authors can easily reproduce them in the future,
	and they can present the document's contents in a different medium,
	e.g. with interactive controls. This paper describes a software framework
	for authoring and distributing these integrated, dynamic documents
	that contain text, code, data, and any auxiliary content needed to
	recreate the computations. The documents are dynamic in that the
	contents, including figures, tables, etc., can be recalculated each
	time a view of the document is generated. Our model treats a dynamic
	document as a master or ``source'' document from which one can generate
	different views in the form of traditional, derived documents for
	different audiences. We introduce the concept of a compendium as
	both a container for the different elements that make up the document
	and its computations (i.e. text, code, data, ...), and as a means
	for distributing, managing and updating the collection. The step
	from disseminating analyses via a compendium to reproducible research
	is a small one. By reproducible research, we mean research papers
	with accompanying software tools that allow the reader to directly
	reproduce the results and employ the methods that are presented in
	the research paper. Some of the issues involved in paradigms for
	the production, distribution and use of such reproducible research
	are discussed.},
  eprint = {http://www.bepress.com/bioconductor/paper2/},
  file = {:Reproducible_Research/GentlemanLang_2004.pdf:PDF},
  owner = {xtof},
  timestamp = {2008.03.14},
  url = {http://www.bepress.com/bioconductor/paper2/}
}

@BOOK{Gu_2002,
  title = {{S}moothing {S}pline {A}nova {M}odels},
  publisher = {Springer},
  year = {2002},
  author = {Chong Gu},
  file = {Gu_2002.pdf:SmoothAndKernel/Gu_2002.pdf:PDF},
  owner = {xtof},
  timestamp = {2008.03.14}
}

@BOOK{HastieEtAl_2009,
  title = {{T}he {E}lements of {S}tatistical {L}earning: {D}ata {M}ining, {I}nference,
	and {P}rediction ({S}econd {E}dition)},
  publisher = {Springer},
  year = {2009},
  author = {Trevor Hastie and Robert Tibshirani and Jerome Friedman},
  edition = {second},
  note = {Available at: \url{http://www-stat.stanford.edu/~hastie/Papers/ESLII.pdf}.},
  file = {HastieEtAl_2009.pdf:Statistics/HastieEtAl_2009.pdf:PDF},
  owner = {xtof},
  timestamp = {2009.10.27},
  url = {http://www-stat.stanford.edu/~tibs/ElemStatLearn/}
}

@ARTICLE{Heetderks_1978,
  author = {Heetderks, W. J.},
  title = {Criteria for evaluating multiunit spike separation techniques},
  journal = {Biological Cybernetics},
  year = {1978},
  volume = {29},
  pages = {215-220},
  note = {10.1007/BF00337278},
  abstract = {Multi-unit neural recordings often occur in neurophysiological studies,
	and a wide variety of techniques have been proposed to separate the
	multi-unit activity. In this paper we propose a method for evaluating
	the power of various multi-unit sorting techniques. The analysis
	can also be applied to a data set to determine whether a given multi-unit
	isolation technique can isolate a given set of wavelets to a specified
	statistical standard. The apparent separation matrix described in
	the paper is then used to evaluate the ability of four multi-unit
	isolation techniques to resolve a population of 8 units simultaneously
	recorded in the medial articular nerve of the cat.},
  file = {Heetderks_1978.pdf:Spike_Sorting/Heetderks_1978.pdf:PDF},
  issn = {0340-1200},
  issue = {4},
  keyword = {Computer Science},
  owner = {xtof},
  publisher = {Springer Berlin / Heidelberg},
  timestamp = {2011.03.04},
  url = {http://dx.doi.org/10.1007/BF00337278}
}

@MANUAL{Hiebeler:2010,
  title = {Matlab / R Reference},
  author = {David Hiebeler},
  month = {may},
  year = {2010},
  note = {Available at: \url{http://www.math.umaine.edu/~hiebeler/comp/matlabR.html}},
  file = {Hiebeler\:2010.pdf:R_stuff/Hiebeler\:2010.pdf:PDF},
  owner = {xtof},
  timestamp = {2011.05.02},
  url = {http://www.math.umaine.edu/~hiebeler/comp/matlabR.html}
}

@ARTICLE{HubbardVetter_1996,
  author = {Hubbard, Raymond and Vetter, Daniel E.},
  title = {An empirical comparison of published replication research in accounting,
	economics, finance, management, and marketing},
  journal = {Journal of Business Research},
  year = {1996},
  volume = {35},
  pages = {153--164},
  number = {2},
  month = feb,
  abstract = {The results of a large-scale content analysis of 18 leading business
	journals covering the 22-year time period 1970 to 1991 show published
	replication and extension research is uncommon in the business disciplines.
	For example, such research typically constitutes less than 10% of
	published empirical work in the accounting, economics, and finance
	areas, and 5% or less in the management and marketing fields. Further,
	when such work is undertaken the results usually conflict with existing
	findings. This raises the prospect that empirical results in these
	areas may be of limited value for guiding the development of business
	theory and practice. Strategies for cultivating a replication research
	tradition to facilitate knowledge development in the business disciplines
	are suggested.},
  file = {HubbardVetter_1996.pdf:Reproducible_Research/HubbardVetter_1996.pdf:PDF},
  issn = {0148-2963},
  owner = {xtof},
  timestamp = {2011.01.24},
  url = {http://www.sciencedirect.com/science/article/B6V7S-3VV68XR-S/2/993cb1031b94043b26827913e102b65b}
}

@ARTICLE{IhakaGentleman_1996,
  author = {Ihaka, R and Gentleman, R},
  title = {{R}: {A} {L}anguage for {D}ata {A}nalysis and {G}raphics},
  journal = {Journal of Graphical and Computational Statistics},
  year = {1996},
  volume = {5},
  pages = {299--314},
  abstract = {In this article we discuss our experience designing and implementing
	a statistical computing language. In developing this new language,
	we sought to combine what we felt were useful features from two existing
	computer languages. We feel that the new language provides advantages
	in the areas of portability, computational efficiency, memory management,
	and scoping.},
  file = {IhakaGentleman_1996.pdf:Statistics/IhakaGentleman_1996.pdf:PDF},
  owner = {xtof},
  timestamp = {2008.03.14},
  url = {http://links.jstor.org/sici?sici=1061-8600%28199609%295%3A3%3C299%3ARALFDA%3E2.0.CO%3B2-D}
}

@ARTICLE{JouclaEtAl_2010,
  author = {Sebastien Joucla and Andreas Pippow and Peter Kloppenburg and Christophe
	Pouzat},
  title = {{Q}uantitative estimation of calcium dynamics from ratiometric measurements:
	{A} direct, non-ratioing, method.},
  journal = {Journal of Neurophysiology},
  year = {2010},
  volume = {103},
  pages = {1130--1144},
  abstract = {Measuring variations of intracellular free calcium concentration through
	the changes in fluorescence of a calcium sensitive dye is a ubiquitous
	technique in neuroscience. Despite its popularity, confidence intervals
	(CIs) on the estimated parameters of calcium dynamics models are
	seldom given. To address this issue, we have developed a 2-stage
	model for ratiometric measurements obtained with a CCD camera. Its
	first element embeds a parametric calcium dynamics model into a fluorescence
	intensity model, and its second element describes probabilistically
	the fluorescence measurements by a CCD camera. Using Monte-Carlo
	simulations, we first show that the classical ratiometric transformation
	gives reliable CIs for time constants only, and not baseline calcium
	concentration nor influx. We then introduce a direct method, which
	consists of fitting directly and simultaneously the fluorescence
	transients at both wavelengths, without any data ratioing. This approach
	uses a probabilistic description of the camera, leading to the construction
	of meaningful CIs for the calcium parameters. Moreover, using approaches
	inspired by constrained linear regression, we can take into account
	the finite precision on calibrated parameters (such as the dye dissociation
	constant in the cell). These key features are illustrated on simulated
	data using Monte-Carlo simulations. We illustrate moreover the strength
	of the direct method on experimental recordings from insect olfactory
	interneurons. In particular, we show how to handle a time-dependent
	buffer concentration, thereby considerably improving our goodness
	of fit. The direct method was implemented in the open-source software
	R and is freely distributed in the CalciOMatic package.},
  doi = {10.1152/jn.00414.2009},
  file = {JouclaEtAl_2010.pdf:Calcium/JouclaEtAl_2010.pdf:PDF},
  owner = {xtof},
  timestamp = {2009.12.02},
  url = {http://intl-jn.physiology.org/cgi/content/short/103/2/1130}
}

@BOOK{Knuth_1984,
  title = {The TeXbook},
  publisher = {Addison-Wesley},
  year = {1984},
  author = {Donald E. Knuth},
  pages = {x+483},
  address = {Reading, Massachusetts},
  owner = {xtof},
  timestamp = {2011.01.31}
}

@ARTICLE{Knuth_1984b,
  author = {Knuth, Donald E.},
  title = {Literate Programming},
  journal = {The Computer Journal},
  year = {1984},
  volume = {27},
  pages = {97-111},
  number = {2},
  note = {Reprint available at: \url{http://www.literateprogramming.com/knuthweb.pdf}.},
  doi = {10.1093/comjnl/27.2.97},
  file = {Knuth_1984b.pdf:Reproducible_Research/Knuth_1984b.pdf:PDF},
  owner = {xtof},
  timestamp = {2011.01.31}
}

@TECHREPORT{KoenkerZeileis_2007,
  author = {Koenker, Roger and Zeileis, Achim},
  title = {Reproducible Econometric Research. A Critical Review of the State
	of the Art.},
  institution = {Department of Statistics and Mathematics, WU Vienna University of
	Economics and Business, Vienna.},
  year = {2007},
  type = {Research Report Series / Department of Statistics and Mathematics},
  number = {60},
  note = {Available at: \url{http://epub.wu.ac.at/638/}},
  abstract = {Recent software developments are reviewed from the vantage point of
	reproducible econometric research. We argue that the emergence of
	new tools, particularly in the open-source community, have greatly
	eased the burden of documenting and archiving both empirical and
	simulation work in econometrics. Some of these tools are highlighted
	in the discussion of three small replication exercises.},
  file = {KoenkerZeileis_2007.pdf:Reproducible_Research/KoenkerZeileis_2007.pdf:PDF},
  owner = {xtof},
  timestamp = {2011.01.19},
  url = {http://epub.wu.ac.at/638/}
}

@MANUAL{Kuhn_2010,
  title = {odfWeave: Sweave processing of Open Document Format (ODF) files},
  author = {Max Kuhn},
  year = {2010},
  note = {R package version 0.7.17},
  url = {http://CRAN.R-project.org/package=odfWeave}
}

@BOOK{Lamport_1986,
  title = {LaTeX: A Document Preparation System},
  publisher = {Addison-Wesley},
  year = {1986},
  author = {Leslie Lamport},
  address = {Reading, Massachusetts},
  owner = {xtof},
  timestamp = {2011.01.31}
}

@BOOK{Lehmann+Romano:2005,
  title = {Testing {S}tatistical {H}ypothesis},
  publisher = {Springer},
  year = {2005},
  author = {E. L. Lehmann and Joseph P. Romano},
  edition = {3},
  owner = {xtof},
  timestamp = {2011.02.28}
}

@INPROCEEDINGS{Leisch_2003b,
  author = {Friedrich Leisch},
  title = {{S}weave and {B}eyond: {C}omputations on {T}ext {D}ocuments},
  booktitle = {Proceedings of the 3rd International Workshop on Distributed Statistical
	Computing, Vienna, Austria},
  year = {2003},
  editor = {Kurt Hornik and Friedrich Leisch and Achim Zeileis},
  note = {{ISSN 1609-395X}},
  abstract = {Sweave is a tool that allows to embed R code in LaTeX documents. The
	code can be evaluated and the resulting console output, figures and
	tables are automatically inserted into the final document. In this
	paper we first give an introduction into the Sweave file format,
	and then demonstrate how to use these files as R package user guides
	known as package vignettes. Finally we give an outlook on the design
	of the next generation of Sweave, which uses S4 classes and methods
	and will allow for much more complex computations on text documents.},
  file = {Leisch_2003b.pdf:/media/usbdisk-1/PaperPDF/Reproducible_Research/Leisch_2003b.pdf:PDF},
  owner = {xtof},
  timestamp = {2008.03.14},
  url = {http://www.ci.tuwien.ac.at/Conferences/DSC-2003/Proceedings/}
}

@INPROCEEDINGS{Leisch_2002b,
  author = {Friedrich Leisch},
  title = {{S}weave: {D}ynamic {G}eneration of {S}tatistical {R}eports {U}sing
	{L}iterate {D}ata {A}nalysis},
  booktitle = {Compstat 2002 --- Proceedings in Computational Statistics},
  year = {2002},
  editor = {Wolfgang H{\"a}rdle and Bernd R{\"o}nz},
  pages = {575--580},
  publisher = {Physica Verlag, Heidelberg},
  note = {Available at: \url{http://www.statistik.uni-muenchen.de/~leisch/Sweave/}},
  file = {Leisch_2002b.pdf:Reproducible_Research/Leisch_2002b.pdf:PDF},
  owner = {xtof},
  timestamp = {2008.10.28},
  url = {http://www.stat.uni-muenchen.de/~leisch/Sweave}
}

@ARTICLE{Leisch_2003,
  author = {Friedrich Leisch},
  title = {{S}weave, {P}art {II}: {P}ackage {V}ignettes},
  journal = {R News},
  year = {2003},
  volume = {3},
  pages = {21--24},
  number = {2},
  month = {October},
  owner = {xtof},
  timestamp = {2008.03.14},
  url = {http://CRAN.R-project.org/doc/Rnews/}
}

@ARTICLE{Leisch_2002,
  author = {Friedrich Leisch},
  title = {{S}weave, {P}art {I}: {M}ixing {R} and {\LaTeX}},
  journal = {R News},
  year = {2002},
  volume = {2},
  pages = {28--31},
  number = {3},
  month = {December},
  owner = {xtof},
  timestamp = {2008.03.14},
  url = {http://CRAN.R-project.org/doc/Rnews/}
}

@ARTICLE{Lewicki_1998,
  author = {Michael S Lewicki},
  title = {{A} review of methods for spike sorting: the detection and classification
	of neural action potentials},
  journal = {Network: Computation in Neural Systems},
  year = {1998},
  volume = {9},
  pages = {R53-R78},
  number = {4},
  note = {Available at: \url{http://www.cnbc.cmu.edu/cplab/papers/Lewicki-Network-98.pdf}},
  abstract = {The detection of neural spike activity is a technical challenge that
	is a prerequisite for studying many types of brain function. Measuring
	the activity of individual neurons accurately can be difficult due
	to large amounts of background noise and the difficulty in distinguishing
	the action potentials of one neuron from those of others in the local
	area. This article reviews algorithms and methods for detecting and
	classifying action potentials, a problem commonly referred to as
	spike sorting. The article first discusses the challenges of measuring
	neural activity and the basic issues of signal detection and classification.
	It reviews and illustrates algorithms and techniques that have been
	applied to many of the problems in spike sorting and discusses the
	advantages and limitations of each and the applicability of these
	methods for different types of experimental demands. The article
	is written both for the physiologist wanting to use simple methods
	that will improve experimental yield and minimize the selection biases
	of traditional techniques and for those who want to apply or extend
	more sophisticated algorithms to meet new experimental challenges.},
  discloc = {/media/usbdisk-1/PaperPDF/Spike_Sorting/Lewicki_1998.pdf},
  file = {Lewicki_1998.pdf:Spike_Sorting/Lewicki_1998.pdf:PDF},
  owner = {xtof},
  timestamp = {2008.03.14},
  url = {http://www.iop.org/EJ/abstract/0954-898X/9/4/001}
}

@INBOOK{Liebowitz_2009,
  chapter = {Anatomy of a Train Wreck: Causes of the Mortgage Meltdown},
  title = {Housing America: Building Out Of a Crisis},
  publisher = {Transaction Publishers},
  year = {2009},
  editor = {Benjamin Powell, Randall Holcomb},
  author = {Stan J. Liebowitz},
  note = {Available at: \url{http://papers.ssrn.com/sol3/papers.cfm?abstract_id=1211822}},
  abstract = {Why did the mortgage market melt-down so badly? Why were there so
	many defaults when the economy was not particularly weak? Why were
	the securities based upon these mortgages not considered anywhere
	as risky as they actually turned out to be? It is the thesis of this
	paper that, in an attempt to increase homeownership, particularly
	by minorities and the less affluent, an attack on underwriting standards
	was undertaken by virtually every branch of the government since
	the early 1990s. The decline in mortgage underwriting standards was
	universally praised as an 'innovation' in mortgage lending by regulators,
	academic specialists, GSEs, and housing activists. This weakening
	of underwriting standards succeeded in increasing home ownership
	and also the price of housing, helping to lead to a housing price
	bubble. The bubble increased the number of housing speculators with
	estimates indicating that one quarter of all home sales were speculative
	sales prior to the bubble bursting. The recent rise in foreclosures
	is not related to the subprime/prime distinction since both markets
	had similar size increases in foreclosures that occurred at exactly
	the same time. Instead, the adjustable-rate/fixed-rate distinction
	is the key to understanding the rise in foreclosures. This is consistent
	with speculators turning and running when housing prices stopped
	rising. It is not consistent with the nasty-subprime-lender hypothesis
	currently considered to be the cause of the mortgage meltdown.},
  file = {Liebowitz_2009.pdf:Economics/Liebowitz_2009.pdf:PDF},
  keywords = {mortgages, meltdown. foreclosure, flexible lending, defaults, subprime},
  owner = {xtof},
  timestamp = {2011.01.25},
  url = {http://papers.ssrn.com/sol3/papers.cfm?abstract_id=1211822}
}

@MANUAL{Lumley:2006,
  title = {R Fundamentals and Programming Techniques},
  author = {Thomas Lumley},
  year = {2006},
  note = {Available at: \url{http://faculty.washington.edu/tlumley/Rcourse/}},
  file = {Lumley\:2006.pdf:R_stuff/Lumley\:2006.pdf:PDF},
  owner = {xtof},
  timestamp = {2011.05.02},
  url = {http://faculty.washington.edu/tlumley/Rcourse/}
}

@ARTICLE{Massart:1990,
  author = {P. Massart},
  title = {The {T}ight {C}onstant in the {D}voretzky-{K}iefer-{W}olfowitz {I}nequality},
  journal = {Annals of Probability},
  year = {1990},
  volume = {18},
  pages = {1269--1283},
  number = {3},
  abstract = {Let $\hat{F}_n$ denote the empirical distribution function for a sample
	of $n$ i.i.d. random variables with distribution function $F$. In
	1956 Dvoretzky, Kiefer and Wolfowitz proved that $P\big(\sqrt{n}
	\sup_x(\hat{F}_n(x) - F(x)) > \lambda\big) \leq C \exp(-2\lambda^2),$
	where $C$ is some unspecified constant. We show that $C$ can be taken
	as 1 (as conjectured by Birnbaum and McCarty in 1958), provided that
	$\exp(-2\lambda^2) \leq \frac{1}{2}$. In particular, the two-sided
	inequality $P\big(\sqrt{n} \sup_x|\hat{F}_n(x) - F(x)| > \lambda\big)
	\leq 2 \exp(-2\lambda^2)$ holds without any restriction on $\lambda$.
	In the one-sided as well as in the two-sided case, the constants
	cannot be further improved.},
  doi = {10.1214/aop/1176990746},
  file = {Massart\:1990.pdf:Statistics/Massart\:1990.pdf:PDF},
  owner = {xtof},
  timestamp = {2011.02.28},
  url = {http://projecteuclid.org/euclid.aop/1176990746}
}

@TECHREPORT{McCulloughMcKitrick_2009,
  author = {Bruce McCullough and Ross McKitrick},
  title = {Check the Numbers: The Case for Due Diligence in Policy Formation},
  institution = {Fraser Institute},
  year = {2009},
  type = {Research Studies},
  month = {feb},
  note = {Available at: \url{http://www.fraserinstitute.org/research-news/display.aspx?id=12933}},
  abstract = {Empirical research in academic journals is often cited as the basis
	for public policy decisions, in part because people think that the
	journals have checked the accuracy of the research. Yet such work
	is rarely subjected to independent checks for accuracy during the
	peer review process, and the data and computational methods are so
	seldom disclosed that post-publication verification is equally rare.
	This study argues that researchers and journals have allowed habits
	of secrecy to persist that severely inhibit independent replication.
	Non-disclosure of essential research materials may have deleterious
	scientific consequences, but our concern herein is something different:
	the possible negative effects on public policy formation. When a
	piece of academic research takes on a public role, such as becoming
	the basis for public policy decisions, practices that obstruct independent
	replication, such as refusal to disclose data, or the concealment
	of details about computational methods, prevent the proper functioning
	of the scientific process and can lead to poor public decision making.
	This study shows that such practices are surprisingly common, and
	that researchers, users of research, and the public need to consider
	ways to address the situation. We offer suggestions that journals,
	funding agencies, and policy makers can implement to improve the
	transparency of the publication process and enhance the replicability
	of the research that is published.},
  file = {McCulloughMcKitrick_2009.pdf:Reproducible_Research/McCulloughMcKitrick_2009.pdf:PDF},
  howpublished = {Print and web},
  owner = {xtof},
  timestamp = {2011.01.24},
  url = {http://www.fraserinstitute.org/research-news/display.aspx?id=12933}
}

@ARTICLE{McCullough_2007,
  author = {B. D. McCullough},
  title = {Got Replicability? The Journal of Money, Credit and Banking Archive},
  journal = {Econ Journal Watch},
  year = {2007},
  volume = {4},
  pages = {326-337},
  number = {3},
  abstract = {In a paper published in the Journal of Money, Credit and Banking,
	McGeary, Harrison, and I showed that the JMCB’s data+code archive
	of generally did not support the replication of the journal’s published
	results. We recommended several procedures for ensuring that the
	archived data and code would reproduce the published results. The
	JMCB Editors recently adopted a few new procedures, ignoring most
	of the recommendations. This paper checks to see whether the new
	procedures are working. They are not.},
  file = {McCullough_2007.pdf:Reproducible_Research/McCullough_2007.pdf:PDF},
  owner = {xtof},
  timestamp = {2011.01.21},
  url = {http://econjwatch.org/articles/got-replicability-the-journal-of-money-credit-and-banking-archive}
}

@ARTICLE{McCullough_2006,
  author = {B. D. McCullough},
  title = {Section Editor's Introduction},
  journal = {Journal of Economic and Social Measurement},
  year = {2006},
  volume = {31},
  pages = {103--105},
  number = {1-2},
  note = {Available at: \url{http://www.pages.drexel.edu/~bdm25/publications.html}},
  file = {McCullough_2006.pdf:Reproducible_Research/McCullough_2006.pdf:PDF},
  owner = {xtof},
  timestamp = {2011.01.24},
  url = {http://www.pages.drexel.edu/~bdm25/publications.html}
}

@ARTICLE{McCulloughEtAl_2006,
  author = {B. D. McCullough and Kerry Anne McGeary and Teresa Harrison},
  title = {Lessons from the JMCB Archive},
  journal = {Journal of Money, Credit and Banking},
  year = {2006},
  volume = {38},
  pages = {1093-1107},
  number = {4},
  note = {Available at: \url{http://www.pages.drexel.edu/~bdm25/publications.html}},
  file = {McCulloughEtAl_2006.pdf:Reproducible_Research/McCulloughEtAl_2006.pdf:PDF},
  owner = {xtof},
  timestamp = {2011.01.21},
  url = {http://www.pages.drexel.edu/~bdm25/publications.html}
}

@UNPUBLISHED{McShaneWyner_2010,
  author = {Blakeley B. McShane and Abraham J. Wyner},
  title = {A Statistical Analysis of Multiple Temperature Proxies: Are Reconstructions
	of Surface Temperatures Over the Last 1000 Years Reliable?},
  note = {To be published in The Annals of Applied Statistics.},
  year = {2010},
  file = {pre-print:home/xtof/PaperPDF/Climate/McShaneWyner_2010.pdf:PDF},
  owner = {xtof},
  timestamp = {2010.10.05},
  url = {http://www.e-publications.org/ims/submission/index.php/AOAS/user/submissionFile/6695?confirm=63ebfddf}
}

@ARTICLE{NguyenEtAl_2003,
  author = {David P Nguyen and Loren M Frank and Emery N Brown},
  title = {{A}n application of reversible-jump {M}arkov chain {M}onte {C}arlo
	to spike classification of multi-unit extracellular recordings.},
  journal = {Network},
  year = {2003},
  volume = {14},
  pages = {61--82},
  number = {1},
  month = {Feb},
  abstract = {Multi-electrode recordings in neural tissue contain the action potential
	waveforms of many closely spaced neurons. While we can observe the
	action potential waveforms, we cannot observe which neuron is the
	source for which waveform nor how many source neurons are being recorded.
	Current spike-sorting algorithms solve this problem by assuming a
	fixed number of source neurons and assigning the action potentials
	given this fixed number. We model the spike waveforms as an anisotropic
	Gaussian mixture model and present, as an alternative, a reversible-jump
	Markov chain Monte Carlo (MCMC) algorithm to simultaneously estimate
	the number of source neurons and to assign each action potential
	to a source. We derive this MCMC algorithm and illustrate its application
	using simulated three-dimensional data and real four-dimensional
	feature vectors extracted from tetrode recordings of rat entorhinal
	cortex neurons. In the analysis of the simulated data our algorithm
	finds the correct number of mixture components (sources) and classifies
	the action potential waveforms with minimal error. In the analysis
	of real data, our algorithm identifies clusters closely resembling
	those previously identified by a user-dependent graphical clustering
	procedure. Our findings suggest that a reversible-jump MCMC algorithm
	could offer a new strategy for designing automated spike-sorting
	algorithms.},
  keywords = {Action Potentials; Algorithms; Animals; Bayes Theorem; Cluster Analysis;
	Computer Simulation; Electrophysiology; Markov Chains; Models, Neurological;
	Monte Carlo Method; Neurons; Rats},
  owner = {xtof},
  pmid = {12617059},
  timestamp = {2008.03.14}
}

@MISC{NIH_2003,
  author = {NIH},
  title = {NIH Data Sharing Brochure},
  howpublished = {web},
  month = {may},
  year = {2003},
  note = {Available at: \url{http://grants.nih.gov/grants/policy/data_sharing/}},
  file = {:Reproducible_Research/data_sharing_brochure_NIH.pdf:PDF},
  owner = {xtof},
  timestamp = {2011.01.26}
}

@ELECTRONIC{OECD_2007,
  author = {{OECD}},
  month = {apr},
  year = {2007},
  title = {{OECD Principles and Guidelines for Access to Research Data from
	Public Funding}},
  language = {English},
  howpublished = {Web},
  organization = {Organisation for Economic Co-operation and Development},
  note = {Available at: \url{http://www.oecd.org/document/2/0,3343,en_2649_34293_38500791_1_1_1_1,00.html}},
  url = {http://www.oecd.org/document/2/0,3343,en_2649_34293_38500791_1_1_1_1,00.html},
  file = {OECD_2007.pdf:Reproducible_Research/OECD_2007.pdf:PDF},
  owner = {xtof},
  timestamp = {2011.01.27}
}

@MANUAL{Oetiker+:2011,
  title = {The Not So Short Introduction To {\LaTeX2e}},
  author = {Tobias Oetiker and Hubert Partl and Irene Hyna and Elisabeth Schlegl},
  edition = {5.01},
  month = {apr},
  year = {2011},
  note = {Available at: \url{http://www.ctan.org/tex-archive/info/lshort/english}},
  file = {Oetiker+\:2011.pdf:LaTeXstuff/Oetiker+\:2011.pdf:PDF},
  owner = {xtof},
  timestamp = {2011.05.02},
  url = {http://www.ctan.org/tex-archive/info/lshort/english}
}

@TECHREPORT{Peng_2007b,
  author = {Roger Peng},
  title = {REPRODUCIBLE RESEARCH TOOLKIT FOR R},
  institution = {Johns Hopkins University, Dept. of Biostatistics},
  year = {2007},
  type = {Working Paper},
  number = {142},
  month = {may},
  abstract = {We present a collection of R packages for conducting and distributing
	reproducible research using R, Sweave, and LaTeX. The collection
	consists of the cacheSweave, stashR, and SRPM packages which allow
	for the caching of computations in Sweave documents and the distribution
	of those cached computations via remotely accessible key-value databases.
	We describe the caching mechanism used by the cacheSweave package
	and tools that we have developed for authors and readers for the
	purposes of creating and interacting with reproducible documents.},
  file = {Peng_2007b.pdf:Reproducible_Research/Peng_2007b.pdf:PDF},
  owner = {xtof},
  timestamp = {2011.01.21},
  url = {http://www.bepress.com/jhubiostat/paper142}
}

@BOOK{PengDominici_2008,
  title = {Statistical Methods for Environmental Epidemiology with R},
  publisher = {Springer},
  year = {2008},
  author = {Roger D. Peng and Francesca Dominici},
  series = {Use R!},
  owner = {xtof},
  timestamp = {2011.01.20}
}

@ARTICLE{PippowEtAl_2009,
  author = {Andreas Pippow and Andreas Husch and Christophe Pouzat and Peter
	Kloppenburg},
  title = {{D}ifferences of {C}a(2+) handling properties in identified central
	olfactory neurons of the antennal lobe.},
  journal = {Cell Calcium},
  year = {2009},
  volume = {46},
  pages = {87-98},
  number = {2},
  month = {Jun},
  abstract = {Information processing in neurons depends on highly localized Ca(2+)
	signals. The spatial and temporal dynamics of these signals are determined
	by a variety of cellular parameters including the calcium influx,
	calcium buffering and calcium extrusion. Our long-term goal is to
	better understand how intracellular Ca(2+) dynamics are controlled
	and contribute to information processing in defined interneurons
	of the insect olfactory system. The latter has served as an excellent
	model to study general mechanisms of olfaction. Using patch-clamp
	recordings and fast optical imaging in combination with the 'added
	buffer approach', we analyzed the Ca(2+) handling properties of different
	identified neuron types in Periplaneta americana's olfactory system.
	Our focus was on two types of local interneurons (LNs) with significant
	differences in intrinsic electrophysiological properties: (1) spiking
	LNs that generate 'normal' Na(+) driven action potentials and (2)
	non-spiking LNs that do not express voltage-activated Na(+) channels.
	We found that the distinct electrophysiological properties from different
	types of central olfactory interneurons are strongly correlated with
	their cell specific calcium handling properties: non-spiking LNs,
	in which Ca(2+) is the only cation that enters the cell to contribute
	to membrane depolarization, had the highest endogenous Ca(2+) binding
	ratio and Ca(2+) extrusion rate.},
  doi = {10.1016/j.ceca.2009.05.004},
  file = {PippowEtAl_2009.pdf:Calcium/PippowEtAl_2009.pdf:PDF},
  institution = {Institute of Zoology and Physiology, Center for Molecular Medicine
	Cologne (CMMC) and Cologne Excellence Cluster in Aging Associated
	Diseases (CECAD), University of Cologne, Weyertal 119, 50931 Cologne,
	Germany.},
  owner = {xtof},
  pii = {S0143-4160(09)00088-8},
  pmid = {19545897},
  timestamp = {2009.06.29},
  url = {http://dx.doi.org/10.1016/j.ceca.2009.05.004}
}

@ARTICLE{Poggio+Mountcastle:1963,
  author = {Gian F. Poggio and Vernon B. Mountcastle},
  title = {THE FUNCTIONAL PROPERTIES OF VENTROBASAL THALAMIC NEURONSSTUDIED
	IN UNANESTHETIZED MONKEYS},
  journal = {Journal of Neurophysiology},
  year = {1963},
  volume = {26},
  pages = {775--806},
  file = {Poggio+Mountcastle\:1963.pdf:Spike_Sorting/Poggio+Mountcastle\:1963.pdf:PDF},
  owner = {xtof},
  timestamp = {2011.03.04}
}

@ARTICLE{PouzatChaffiol_2009,
  author = {Christophe Pouzat and Antoine Chaffiol},
  title = {{A}utomatic {S}pike {T}rain {A}nalysis and {R}eport {G}eneration.
	{A}n {I}mplementation with {R}, {R2HTML} and {STAR}},
  journal = {J Neurosci Methods},
  year = {2009},
  volume = {181},
  pages = {119--144},
  note = {Pre-print available at: \url{http://sites.google.com/site/spiketrainanalysiswithr/Home/PouzatChaffiol_JNM_2009.pdf?attredirects=0}},
  file = {PouzatChaffiol_2009.pdf:Spike_Train_Analysis/PouzatChaffiol_2009.pdf:PDF},
  owner = {xtof},
  timestamp = {2008.10.24},
  url = {http://sites.google.com/site/spiketrainanalysiswithr/}
}

@ARTICLE{PouzatEtAl_2002,
  author = {Pouzat, C. and Mazor, O. and Laurent, G.},
  title = {{U}sing noise signature to optimize spike-sorting and to assess neuronal
	classification quality.},
  journal = {J Neurosci Methods},
  year = {2002},
  volume = {122},
  pages = {43--57},
  number = {1},
  note = {Pre-print available at: \url{http://www.biomedicale.univ-paris5.fr/physcerv/C_Pouzat/Papers_folder/PouzatEtAl_2002.pdf}},
  abstract = {We have developed a simple and expandable procedure for classification
	and validation of extracellular data based on a probabilistic model
	of data generation. This approach relies on an empirical characterization
	of the recording noise. We first use this noise characterization
	to optimize the clustering of recorded events into putative neurons.
	As a second step, we use the noise model again to assess the quality
	of each cluster by comparing the within-cluster variability to that
	of the noise. This second step can be performed independently of
	the clustering algorithm used, and it provides the user with quantitative
	as well as visual tests of the quality of the classification.},
  doi = {10.1016/S0165-0270(02)00276-5},
  file = {PouzatEtAl_2002.pdf:Spike_Sorting/PouzatEtAl_2002.pdf:PDF},
  owner = {xtof},
  timestamp = {2008.03.14}
}

@MANUAL{R_2010,
  title = {R: A Language and Environment for Statistical Computing},
  author = {{R Development Core Team}},
  organization = {R Foundation for Statistical Computing},
  address = {Vienna, Austria},
  year = {2010},
  note = {{ISBN} 3-900051-07-0},
  url = {http://www.R-project.org/}
}

@BOOK{RamsaySilverman_2005,
  title = {{Functional data analysis}},
  publisher = {Springer},
  year = {2005},
  author = {Ramsay, J.O. and Silverman, B.W.},
  series = {Springer Series in Statistics},
  file = {RamsaySilverman_2005.pdf:Books/RamsaySilverman_2005.pdf:PDF;/home/xtof/PaperPDF/Books/RamsaySilverman_2005.pdf::},
  isbn = {9780387400808},
  lccn = {2005923773},
  owner = {xtof},
  timestamp = {2011.02.16}
}

@BOOK{Ripley_1996,
  title = {{P}attern {R}ecognition and {N}eural {N}etworks},
  publisher = {Cambridge University Press},
  year = {1996},
  author = {Ripley, B. D.},
  owner = {xtof},
  timestamp = {2008.03.14}
}

@TECHREPORT{RossiniLeisch_2003,
  author = {Rossini, Anthony and Leisch, Friedrich},
  title = {{L}iterate {S}tatistical {P}ractice},
  institution = {University of Washington},
  year = {2003},
  type = {UW Biostatistics Working Paper Series},
  number = {194},
  abstract = {Literate Statistical Practice (LSP, Rossini, 2001) describes an approach
	for creating self-documenting statistical results. It applies literate
	programming (Knuth, 1992) and related techniques in a natural fashion
	to the practice of statistics. In particular, documentation, specification,
	and descriptions of results are written concurrently with writing
	and evaluation of statistical programs. We discuss how and where
	LSP can be integrated into practice and illustrate this with an example
	derived from an actual statistical consulting project. The approach
	is simplified through the use of a comprehensive, open source toolset
	incorporating Noweb, Emacs Speaks Statistics (ESS), Sweave (Ramsey,
	1994; Rossini, et al, 2002; Leisch, 2002; Ihaka and Gentlemen, 1996).
	We conclude with an assessment of LSP for the construction of reproducible,
	auditable, and comprehensible statistical analyses.},
  eprint = {http://www.bepress.com/uwbiostat/paper194/},
  file = {RossiniLeisch_2003.pdf:Reproducible_Research/RossiniLeisch_2003.pdf:PDF},
  owner = {xtof},
  timestamp = {2008.03.14}
}

@TECHREPORT{RossiniEtAl_2003,
  author = {Rossini, Anthony and Tierney, Luke and Li, Na},
  title = {{S}imple {P}arallel {S}tatistical {C}omputing in {R}},
  institution = {University of Washington},
  year = {2003},
  type = {UW Biostatistics Working Paper Series},
  number = {193},
  note = {Available from: \url{http://www.bepress.com/uwbiostat/paper193/}},
  abstract = {Theoretically, many modern statistical procedures are trivial to parallelize.
	However, practical deployment of a parallelized implementation which
	is robust and reliably runs on different computational cluster configurations
	and environments is far from trivial. We present a framework for
	the R statistical computing language that provides a simple yet powerful
	programming interface to a computational cluster. This interface
	allows the development of R functions that distribute independent
	computations across the nodes of the computational cluster. The resulting
	framework allows statisticians to obtain significant speed-ups for
	some computations at little additional development cost. The particular
	implementation can be deployed in heterogeneous computing environments.},
  file = {RossiniEtAl_2003.pdf:/media/usbdisk-1/PaperPDF/Software/RossiniEtAl_2003.pdf:PDF},
  owner = {xtof},
  timestamp = {2008.03.14},
  url = {http://www.bepress.com/uwbiostat/paper193/}
}

@INPROCEEDINGS{Rossini_2001,
  author = {Rossini, A. J.},
  title = {{L}iterate {S}tatistical {A}nalysis},
  booktitle = {Proceedings of the 2nd International Workshop on Distributed Statistical
	Computing, Vienna, Austria},
  year = {2001},
  editor = {Kurt Hornik and Friedrich Leisch},
  note = {{ISSN 1609-395X}},
  abstract = {Literate Statistical Practice (LSP) is an method for statistical practice
	which suggests that documentation and specification occur at the
	same time as statistical coding. It applies literate programming
	(Knuth, 1992) to the practice of statistics. We discuss 2 different
	approaches for LSP, one currently implemented using Emacs with Noweb
	and Emacs Speaks Statistics (ESS), and the other developed based
	on eXtensible Markup Language (XML) tools. The interference needed
	to change an individual's habits comes at a high cost, and good tools
	are critical for encouraging people to switch to a more literate
	style. We discuss why LSP can help, and suggest how ESS can ease
	the burden placed on the analyst.},
  file = {Rossini_2001.pdf:Reproducible_Research/Rossini_2001.pdf:PDF;Rossini_2001.pdf:file\:/home/xtof/PaperPDF/Reproducible_Research/Rossini_2001.pdf:PDF},
  owner = {xtof},
  timestamp = {2008.03.14},
  url = {http://www.ci.tuwien.ac.at/Conferences/DSC-2001/Proceedings/}
}

@ARTICLE{Schmidt:1984,
  author = {Edward M. Schmidt},
  title = {Computer separation of multi-unit neuroelectric data: a review},
  journal = {Journal of Neuroscience Methods},
  year = {1984},
  volume = {12},
  pages = {95 - 111},
  number = {2},
  doi = {DOI: 10.1016/0165-0270(84)90009-8},
  file = {Schmidt\:1984.pdf:Spike_Sorting/Schmidt\:1984.pdf:PDF},
  issn = {0165-0270},
  keywords = {multi-unit spike trains},
  owner = {xtof},
  timestamp = {2011.03.04},
  url = {http://www.sciencedirect.com/science/article/B6T04-4840NB0-M/2/d5156477d87512353cf83b6d6fcc1655}
}

@ARTICLE{SchwabEtAl_2000,
  author = {Schwab, M. and Karrenbach, N. and Claerbout, J.},
  title = {{M}aking scientific computations reproducible},
  journal = {Computing in Science \& Engineering},
  year = {2000},
  volume = {6},
  pages = {61-- 67},
  note = {Preprinty available at: \url{http://sep.stanford.edu/lib/exe/fetch.php?media=sep:research:reproducible:cip.ps}.},
  file = {SchwabEtAl_2000.pdf:Reproducible_Research/SchwabEtAl_2000.pdf:PDF},
  owner = {xtof},
  timestamp = {2010.05.11},
  url = {http://sep.stanford.edu/doku.php?id=sep:research:reproducible}
}

@ARTICLE{Simon:1965,
  author = {William Simon},
  title = {The real-time sorting of neuro-electric action potentials in multiple
	unit studies},
  journal = {Electroencephalography and Clinical Neurophysiology},
  year = {1965},
  volume = {18},
  pages = {192 - 195},
  number = {2},
  abstract = {Description of a method by which action potentials recorded simultaneously
	can be sorted in a moderate size machine in real-time and on-line.},
  comment = {First instance of manual cluster cutting ?},
  doi = {DOI: 10.1016/0013-4694(65)90029-5},
  file = {Simon\:1965.pdf:Spike_Sorting/Simon\:1965.pdf:PDF},
  issn = {0013-4694},
  owner = {xtof},
  timestamp = {2011.03.04},
  url = {http://www.sciencedirect.com/science/article/B6SYX-482YX24-4K/2/ef7b39badf43cc975bf5b1974e95baa6}
}

@TECHREPORT{Stallman_1981,
  author = {Stallman, Richard M.},
  title = {{EMACS: The Extensible, Customizable, Self-Documenting Display Editor}},
  institution = {MIT Artificial Intelligence Laboratory},
  year = {1981},
  number = {AIM-519A},
  note = {Available at: \url{ftp://publications.ai.mit.edu/ai-publications/pdf/AIM-519A.pdf}},
  file = {Stallman_1981.pdf:Software/Stallman_1981.pdf:PDF},
  owner = {xtof},
  timestamp = {2011.01.31}
}

@UNPUBLISHED{Stein_2011,
  author = {Michael L. Stein},
  title = {Editorial},
  note = {Available at: \url{http://www.e-publications.org/ims/submission/index.php/AOAS/user/submissionFile/8887?confirm=6adde642}},
  year = {2010},
  file = {Stein_2011.pdf:Reproducible_Research/Stein_2011.pdf:PDF},
  owner = {xtof},
  timestamp = {2011.01.20}
}

@ARTICLE{Stodden_2009,
  author = {Victoria Stodden},
  title = {ENABLING REPRODUCIBLE RESEARCH: LICENSING FOR SCIENTIFIC INNOVATION},
  journal = {International Journal of Communications Law and Policy},
  year = {2009},
  volume = {13},
  file = {Stodden_2009.pdf:Reproducible_Research/Stodden_2009.pdf:PDF},
  owner = {xtof},
  timestamp = {2011.01.21},
  url = {http://www.ijclp.net/issue_13.html}
}

@ARTICLE{Stodden_2009b,
  author = {Victoria Stodden},
  title = {The Legal Framework for Reproducible Research in the Sciences: Licensing
	and Copyright},
  journal = {IEEE Computing in Science and Engineering},
  year = {2009},
  volume = {11},
  pages = {35-40},
  number = {1},
  month = {jan},
  note = {Available at: \url{http://www.stanford.edu/~vcs/Papers.html}},
  abstract = {As computational researchers increasingly make their results available
	in a reproducible way, and often outside the traditional journal
	publishing mechanism, questions naturally arise with regard to copyright,
	subsequent use and citation, and ownership rights in general. The
	growing number of scientists who release their research publicly
	face a gap in the current licensing and copyright structure, particularly
	on the Internet. Scientific research produces more than the final
	paper: The code, data structures, experimental design and parameters,
	documentation, and figures are all important for scholarship communication
	and result replication. The author proposes the reproducible research
	standard for scientific researchers to use for all components of
	their scholarship that should encourage reproducible scientific investigation
	through attribution, facilitate greater collaboration, and promote
	engagement of the larger community in scientific learning and discovery.},
  file = {Stodden_2009b.pdf:Reproducible_Research/Stodden_2009b.pdf:PDF},
  owner = {xtof},
  timestamp = {2011.01.21},
  url = {http://www.stanford.edu/~vcs/Papers.html}
}

@ARTICLE{TabelowEtAl_2006,
  author = {K. Tabelow and J. Polzehl and H.U. Voss and V. Spokoiny.},
  title = {Analyzing fMRI experiments with structural adaptive smoothing procedures},
  journal = {NeuroImage},
  year = {2006},
  volume = {33},
  pages = {55--62},
  number = {1},
  owner = {xtof},
  timestamp = {2011.01.31}
}

@STANDARD{NSF_2011,
  title = {Proposal and Award Policies and Procedure Guide. Part II -- Award
	\& Admistration guide},
  institution = {The National Science Foundation},
  author = {{The National Science Foundation}},
  howpublished = {web},
  year = {2011},
  note = {Available at: \url{http://www.nsf.gov/pubs/policydocs/pappguide/nsf11001/index.jsp}},
  url = {http://www.nsf.gov/pubs/policydocs/pappguide/nsf11001/index.jsp},
  file = {:Reproducible_Research/aagprint.pdf:PDF},
  owner = {xtof},
  timestamp = {2011.01.26}
}

@ARTICLE{VandewalleEtAl_2009,
  author = {Patrick Vandewalle and Jelena Kovacevic and Martin Vetterli},
  title = {Reproducible Research in Signal Processing - What, why, and how},
  journal = {IEEE Signal Processing Magazine},
  year = {2009},
  volume = {26},
  pages = {37--47},
  number = {3},
  month = {May},
  note = {Available at: \url{http://rr.epfl.ch/17/}},
  abstract = {Have you ever tried to reproduce the results presented in a research
	paper? For many of our current publications, this would unfortunately
	be a challenging task. For a computational algorithm, details such
	as the exact data set, initialization or termination procedures,
	and precise parameter values are often omitted in the publication
	for various reasons, such as a lack of space, a lack of self-discipline,
	or an apparent lack of interest to the readers, to name a few. This
	makes it difficult, if not impossible, for someone else to obtain
	the same results. In our experience, it is often even worse as even
	we are not always able to reproduce our own experiments, making it
	difficult to answer questions from colleagues about details. Following
	are some examples of e-mails we have received: "I just read your
	paper X. It is very completely described, however I am confused by
	Y. Could you provide the implementation code to me for reference
	if possible?" "Hi! I am also working on a project related to X. I
	have implemented your algorithm but cannot get the same results as
	described in your paper. Which values should I use for parameters
	Y and Z?"},
  owner = {xtof},
  timestamp = {2011.01.19},
  url = {http://rr.epfl.ch/17/}
}

@ARTICLE{WallstromEtAl_2008,
  author = {Garrick Wallstrom and Jeffrey Liebner and Robert E. Kass},
  title = {{A}n {I}mplementation of {B}ayesian {A}daptive {R}egression {S}plines
	({BARS}) in {C} with {S} and {R} {W}rappers},
  journal = {Journal of Statistical Software},
  year = {2007},
  volume = {26},
  pages = {1--21},
  number = {1},
  month = {2},
  abstract = {BARS (DiMatteo, Genovese, and Kass 2001) uses the powerful reversible-jump
	MCMC engine to perform spline-based generalized nonparametric regression.
	It has been shown to work well in terms of having small mean-squared
	error in many examples (smaller than known competitors), as well
	as producing visually-appealing fits that are smooth (filtering out
	high-frequency noise) while adapting to sudden changes (retaining
	high-frequency signal). However, BARS is computationally intensive.
	The original implementation in S was too slow to be practical in
	certain situations, and was found to handle some data sets incorrectly.
	We have implemented BARS in C for the normal and Poisson cases, the
	latter being important in neurophysiological and other point-process
	applications. The C implementation includes all needed subroutines
	for fitting Poisson regression, manipulating B-splines (using code
	created by Bates and Venables), and finding starting values for Poisson
	regression (using code for density estimation created by Kooperberg).
	The code utilizes only freely-available external libraries (LAPACK
	and BLAS) and is otherwise self-contained. We have also provided
	wrappers so that BARS can be used easily within S or R.},
  accepted = {2007-02-20},
  bibdate = {2007-02-20},
  coden = {JSSOBK},
  day = {20},
  file = {:SmoothAndKernel/WallstromEtAl_2008.pdf:PDF;barsP.tar.gz\: barsP source code:http\://www.jstatsoft.org/v26/i01/supp/2:URL;barsN.tar.gz\: barsN source code:http\://www.jstatsoft.org/v26/i01/supp/1:URL},
  issn = {1548-7660},
  owner = {xtof},
  submitted = {2004-06-25},
  timestamp = {2008.03.23},
  url = {http://www.jstatsoft.org/v26/i01}
}

@ARTICLE{Waltemath+:2011,
  author = {Waltemath, Dagmar AND Adams, Richard AND Beard, Daniel A. AND Bergmann,
	Frank T. AND Bhalla, Upinder S. AND Britten, Randall AND Chelliah,
	Vijayalakshmi AND Cooling, Michael T. AND Cooper, Jonathan AND Crampin,
	Edmund J. AND Garny, Alan AND Hoops, Stefan AND Hucka, Michael AND
	Hunter, Peter AND Klipp, Edda AND Laibe, Camille AND Miller, Andrew
	K. AND Moraru, Ion AND Nickerson, David AND Nielsen, Poul AND Nikolski,
	Macha AND Sahle, Sven AND Sauro, Herbert M. AND Schmidt, Henning
	AND Snoep, Jacky L. AND Tolle, Dominic AND Wolkenhauer, Olaf AND
	Le Novère, Nicolas},
  title = {Minimum Information About a Simulation Experiment (MIASE)},
  journal = {PLoS Comput Biol},
  year = {2011},
  volume = {7},
  pages = {e1001122},
  number = {4},
  month = {04},
  abstract = {Reproducibility of experiments is a basic requirement for science.
	Minimum Information (MI) guidelines have proved a helpful means of
	enabling reuse of existing work in modern biology. The Minimum Information
	Required in the Annotation of Models (MIRIAM) guidelines promote
	the exchange and reuse of biochemical computational models. However,
	information about a model alone is not sufficient to enable its efficient
	reuse in a computational setting. Advanced numerical algorithms and
	complex modeling workflows used in modern computational biology make
	reproduction of simulations difficult. It is therefore essential
	to define the core information necessary to perform simulations of
	those models. The Minimum Information About a Simulation Experiment
	(MIASE, Glossary in Box 1) describes the minimal set of information
	that must be provided to make the description of a simulation experiment
	available to others. It includes the list of models to use and their
	modifications, all the simulation procedures to apply and in which
	order, the processing of the raw numerical results, and the description
	of the final output. MIASE allows for the reproduction of any simulation
	experiment. The provision of this information, along with a set of
	required models, guarantees that the simulation experiment represents
	the intention of the original authors. Following MIASE guidelines
	will thus improve the quality of scientific reporting, and will also
	allow collaborative, more distributed efforts in computational modeling
	and simulation of biological processes.},
  doi = {10.1371/journal.pcbi.1001122},
  file = {Waltemath+\:2011.pdf:Reproducible_Research/Waltemath+\:2011.pdf:PDF},
  owner = {xtof},
  publisher = {Public Library of Science},
  timestamp = {2011.05.02},
  url = {http://dx.doi.org/10.1371%2Fjournal.pcbi.1001122}
}

@BOOK{Wasserman_2006,
  title = {{A}ll of {N}onparametric {S}tatistics},
  publisher = {Springer},
  year = {2006},
  author = {Larry Wasserman},
  file = {Complete book:home/xtof/PaperPDF/Books/Wasserman_2006.pdf:PDF},
  owner = {xtof},
  timestamp = {2008.10.02}
}

@ELECTRONIC{WelcomeTrust_2010,
  author = {{Welcome Trust}},
  month = {aug},
  year = {2010},
  title = {Policy on data management and sharing},
  language = {English},
  howpublished = {Web site},
  organization = {The Welcome Trust},
  note = {Available at: \url{http://www.wellcome.ac.uk/About-us/Policy/Policy-and-position-statements/WTX035043.htm}},
  url = {http://www.wellcome.ac.uk/About-us/Policy/Policy-and-position-statements/WTX035043.htm},
  owner = {xtof},
  timestamp = {2011.01.27}
}

@ARTICLE{WoodEtAl_2004,
  author = {Frank Wood and Michael J Black and Carlos Vargas-Irwin and Matthew
	Fellows and John P Donoghue},
  title = {{O}n the variability of manual spike sorting.},
  journal = {IEEE Trans Biomed Eng},
  year = {2004},
  volume = {51},
  pages = {912--918},
  number = {6},
  month = {Jun},
  abstract = {The analysis of action potentials, or "spikes," is central to systems
	neuroscience research. Spikes are typically identified from raw waveforms
	manually for off-line analysis or automatically by human-configured
	algorithms for on-line applications. The variability of manual spike
	"sorting" is studied and its implications for neural prostheses discussed.
	Waveforms were recorded using a micro-electrode array and were used
	to construct a statistically similar synthetic dataset. Results showed
	wide variability in the number of neurons and spikes detected in
	real data. Additionally, average error rates of 23\% false positive
	and 30\% false negative were found for synthetic data.},
  file = {WoodEtAl_2004.pdf:Spike_Sorting/WoodEtAl_2004.pdf:PDF},
  keywords = {Action Potentials; Algorithms; Animals; Diagnosis, Computer-Assisted;
	Electroencephalography; False Negative Reactions; False Positive
	Reactions; Haplorhini; Motor Cortex; Neurons; Observer Variation;
	Pattern Recognition, Automated; Reproducibility of Results; Sensitivity
	and Specificity; Signal Processing, Computer-Assisted; Task Performance
	and Analysis; User-Computer Interface},
  owner = {xtof},
  pmid = {15188858},
  timestamp = {2008.03.14}
}

@comment{jabref-meta: selector_publisher:}

@comment{jabref-meta: selector_author:}

@comment{jabref-meta: selector_journal:}

@comment{jabref-meta: selector_keywords:}

